참조한 자료

[owahltinez - camerax-tflite](https://github.com/owahltinez/camerax-tflite)

[Anupam Chugh - Image Classification on Android with TensorFlow Lite and CameraX]( https://heartbeat.fritz.ai/image-classification-on-android-with-tensorflow-lite-and-camerax-4f72e8fdca79)

전에 과제에서 만들었던 자바 코드는 솔직히 텐서플로우에서 제공한 샘플 코드에 tflite 파일이랑 레이블 파일 바꿔주고 본문의 코드만 맞게 살짝 바꿔준 것이라 온전히 내가 짠 코드라고 할 수 없기 때문에 코틀린 버전으로 바꿀 겸 여러 자료를 참조해서 다시 만들어봤다. 

```kotlin 
package com.example.cameraxappnative

import android.content.Context
import android.content.res.AssetManager
import android.graphics.Bitmap
import android.os.SystemClock
import android.util.Log
import com.google.android.gms.tasks.Task
import com.google.android.gms.tasks.Tasks
import org.json.JSONArray
import org.json.JSONException
import org.json.JSONObject
import org.tensorflow.lite.Interpreter
import java.io.FileInputStream
import java.io.IOException
import java.io.InputStreamReader
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.channels.FileChannel
import java.util.*
import java.util.concurrent.Callable
import java.util.concurrent.ExecutorService
import java.util.concurrent.Executors
import kotlin.collections.ArrayList

class TFLiteClassifier(private val context: Context){
    private lateinit var interpreter: Interpreter
    private var isInitialized = false

    var labels = ArrayList<String>()

    private val executorService: ExecutorService = Executors.newCachedThreadPool()

    private var inputImageWidth: Int = 0
    private var inputImageHeight: Int = 0
    private var modelInputSize: Int = 0

    fun initialize(): Task<Void> {
        return Tasks.call(
            executorService,
            Callable<Void> {
                initializeInterpreter()
                null
            }
        )
    }

    @Throws(IOException::class)
    private fun initializeInterpreter() {
        val assetManager = context.assets
        val model = loadModelFile(assetManager, "trained_model.tflite")

        labels = loadLines(context, "parrot_classifier_labels.txt")
        val options = Interpreter.Options()
        val interpreter = Interpreter(model, options)

        val inputShape = interpreter.getInputTensor(0).shape()
        inputImageWidth = inputShape[1]
        inputImageHeight = inputShape[2]
        modelInputSize = FLOAT_TYPE_SIZE * inputImageWidth * inputImageHeight * CHANNEL_SIZE

        this.interpreter = interpreter

        isInitialized = true

    }

    @Throws(IOException::class)
    private fun loadModelFile(assetManager: AssetManager, filename: String): ByteBuffer{
        val fileDescriptor = assetManager.openFd(filename)
        val fileInputStream = FileInputStream(fileDescriptor.fileDescriptor)
        val fileChannel = fileInputStream.channel
        val startOffset = fileDescriptor.startOffset
        val declaredLength = fileDescriptor.declaredLength
        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
    }

    @Throws(IOException::class)
    fun loadLines(context: Context, filename: String): ArrayList<String>{
        val scanner = Scanner(InputStreamReader(context.assets.open(filename)))
        val labels = ArrayList<String>()
        while (scanner.hasNextLine()){
            labels.add(scanner.nextLine())
        }
        scanner.close()
        return labels
    }

    private fun getMaxResult(result: FloatArray): Int{
        val maxIndex = result.indexOf(result.max()!!)
        return if (maxIndex == -1) 0 else maxIndex
    }

    fun classify(bitmapImaage: Bitmap): JSONObject{
        check(isInitialized) {"The interpreter mush be initialized first."}
        val byteBuffer =
            Bitmap.createScaledBitmap(bitmapImaage, inputImageWidth, inputImageHeight, true)
                .convertBitmapToByteBuffer()

        val output = Array(1){FloatArray(labels.size)}
        val startTime = SystemClock.uptimeMillis()
        interpreter?.run(byteBuffer, output)
        val endTime = SystemClock.uptimeMillis()

        var inferenceTime = endTime - startTime
        var index = getMaxResult(output[0])
        var result = JSONObject()

        try{
            result.put("time", inferenceTime)
            result.put("index", index)

            val jsonArray: JSONArray = JSONArray()
            for(idx in labels.indices){
                val obj: JSONObject = JSONObject()
                obj.put(labels[idx], output[0][idx])
                jsonArray.put(obj)
            }

            result.put("results", jsonArray)

        } catch (exception: JSONException){
            Log.e(TAG, "Exception occurred during constructing a JSON object -> ", exception)
        }

        return result
    }

    private fun Bitmap.convertBitmapToByteBuffer(): ByteBuffer{
        val byteBuffer = ByteBuffer.allocateDirect((modelInputSize))
        byteBuffer.order(ByteOrder.nativeOrder())

        val pixels = IntArray(inputImageWidth * inputImageHeight)
        this.getPixels(pixels, 0, width, 0, 0, width, height)
        var pixel = 0
        for(i in 0 until inputImageWidth){
            for(j in 0 until inputImageHeight){
                val pixelValue = pixels[pixel++]

                byteBuffer.putFloat(((pixelValue shr 16 and 0xFF) - IMAGE_MEAN) / IMAGE_STD)
                byteBuffer.putFloat(((pixelValue shr 8 and 0xFF) - IMAGE_MEAN) / IMAGE_STD)
                byteBuffer.putFloat(((pixelValue and 0xFF) - IMAGE_MEAN) / IMAGE_STD)
            }
        }

        this.recycle()

        return byteBuffer
    }

    companion object {
        private const val TAG ="Parrot_TfLiteClassifier"
        private const val FLOAT_TYPE_SIZE = 4
        private const val CHANNEL_SIZE = 3
        private const val IMAGE_MEAN = 127.5f
        private const val IMAGE_STD = 127.5f
    }
}
```

```kotlin 
private lateinit var interpreter: Interpreter
private var isInitialized = false

var labels = ArrayList<String>()

private val executorService: ExecutorService = Executors.newCachedThreadPool()

private var inputImageWidth: Int = 0
private var inputImageHeight: Int = 0
private var modelInputSize: Int = 0

interpreter의 경우 tflite파일을 읽어서 안에 있는 텐서플로우 그래프로 연산을 진행하는 객체라고 보면 된다. 
isInitialized는 interpreter가 초기화 되었는지를 체크할때 쓰는 변수이다.
labels는 레이블 리스트이다. 
executorService는 하나 이상의 비동적인 작업의 흐름을 추적 할 수 있는 Future 객체를 만들거나 종료하는 메소드를 제공한다. 4번 리포트 참고.
inputImageWidth, inputImageHeight는 실시간으로 들어오는 프레임의 너비와 높이에 대한 값이다. 
modelInputSize는 분류 과정 중에 입력으로 들어오는 비트맵을 바이트버퍼로 바꿀때 바이트버퍼의 크기를 나타낸다. 
```

[곰팡이 먼지연구소 - JAVA ExecutorService 관련 공부](https://gompangs.tistory.com/entry/JAVA-ExecutorService-%EA%B4%80%EB%A0%A8-%EA%B3%B5%EB%B6%80)

```kotlin 
companion object {
        private const val TAG ="Parrot_TfLiteClassifier"
        private const val FLOAT_TYPE_SIZE = 4
        private const val CHANNEL_SIZE = 3
        private const val IMAGE_MEAN = 127.5f
        private const val IMAGE_STD = 127.5f
    }

TAG는 Log를 찍을때 사용하는 태그이다.
FLOAT_TYPE_SIZE은 입력 데이터 타입이 얼마나 많은 바이트를 요구하는지를 가리키는데 float32를 사용하므로 여기서는 4bytes를 나타낸다. 
CHANNEL_SIZE는 여기서는 R,G,B 3개의 채널을 가리킨다.
IMAGE_MEAN, IMAGE_STD는 픽셀 컬러 값이 -1, 1을 갖도록 정규화하는데 쓰이는 상수이다. 255를 2로 나누면 127.5가 나온다. 
```

```kotlin 
fun initialize(): Task<Void> {
        return Tasks.call(
            executorService,
            Callable<Void> {
                initializeInterpreter()
                null
            }
        )
    }

    @Throws(IOException::class)
    private fun initializeInterpreter() {
        val assetManager = context.assets
        val model = loadModelFile(assetManager, "trained_model.tflite")

        labels = loadLines(context, "parrot_classifier_labels.txt")
        val options = Interpreter.Options()
        val interpreter = Interpreter(model, options)

        val inputShape = interpreter.getInputTensor(0).shape()
        inputImageWidth = inputShape[1]
        inputImageHeight = inputShape[2]
        modelInputSize = FLOAT_TYPE_SIZE * inputImageWidth * inputImageHeight * CHANNEL_SIZE

        this.interpreter = interpreter

        isInitialized = true

    }

	@Throws(IOException::class)
    private fun loadModelFile(assetManager: AssetManager, filename: String): ByteBuffer{
        val fileDescriptor = assetManager.openFd(filename)
        val fileInputStream = FileInputStream(fileDescriptor.fileDescriptor)
        val fileChannel = fileInputStream.channel
        val startOffset = fileDescriptor.startOffset
        val declaredLength = fileDescriptor.declaredLength
        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
    }

 	@Throws(IOException::class)
    fun loadLines(context: Context, filename: String): ArrayList<String>{
        val scanner = Scanner(InputStreamReader(context.assets.open(filename)))
        val labels = ArrayList<String>()
        while (scanner.hasNextLine()){
            labels.add(scanner.nextLine())
        }
        scanner.close()
        return labels
    }

Tasks.call 비동기적인 Operation에 관한 기능을 담고 있는 추상 클래스. 앱의 다른 기능(프리뷰 등)과 별개로 interpreter를 초기화 하기 위해서 이런 식으로 호출한다.
initializeInterpreter 안에서는 assets 폴더에 있는 tflite 파일을 읽어서 interpreter로 만들고 label이 적혀있는 텍스트 파일을 읽어서 label의 리스트로 만든다. 

AssetManager.openFd를 열려고 하는 asset를 string으로 받아서 AssetFileDescriptor를 리턴한다. assets에 있는 파일에 대한 접근 방법을 제공한다. 
FileInputStream은 FileDescriptor을 입력으로 받아서 파일 시스템에 있는 파일에 대한 연결을 담당한다. 
getChannel은 FileChannel 객체를 리턴하는데 FileChannel은 파일을 Reading, Writing, Mapping, Manipulating 할 수 있게 한다. 
getStartOffset은 asset의 데이터가 시작되는 바이트 오프셋을 반환한다. 
AssetFileDescriptor.DeclaredLength 프로퍼티의 경우 AssetFileDescriptor가 만들어질때 바이트의 실제 숫자를 리턴한다. 
FileChannel.map은 getStartOffset에서 AssetFileDescriptor.DeclaredLength 만큼의 영역을 메모리에 매핑한다. 

InputStreamReader은 바이트 스트림에서 문자 스트림으로의 다리 역할을 한다. 레이블이 텍스트 파일로 되어 있으므로 이 파일의 바이트 스트림을 문자로 바꾸기 위한 역할을 한다. 
Scanner로 파일의 내용을 토큰 단위로 끊어 읽는다. White space가 Default Delimiter pattern으로 지정되어 있는데 레이블이 각각 한줄씩("\n"이 붙어 있음) 적혀 있다. 
```

```kotlin 
private fun getMaxResult(result: FloatArray): Int{
        val maxIndex = result.indexOf(result.max()!!)
        return if (maxIndex == -1) 0 else maxIndex
    }

    fun classify(bitmapImaage: Bitmap): JSONObject{
        check(isInitialized) {"The interpreter mush be initialized first."}
        val byteBuffer =
            Bitmap.createScaledBitmap(bitmapImaage, inputImageWidth, inputImageHeight, true)
                .convertBitmapToByteBuffer()

        val output = Array(1){FloatArray(labels.size)}
        val startTime = SystemClock.uptimeMillis()
        interpreter?.run(byteBuffer, output)
        val endTime = SystemClock.uptimeMillis()

        var inferenceTime = endTime - startTime
        var index = getMaxResult(output[0])
        var result = JSONObject()

        try{
            result.put("time", inferenceTime)
            result.put("index", index)

            val jsonArray: JSONArray = JSONArray()
            for(idx in labels.indices){
                val obj: JSONObject = JSONObject()
                obj.put(labels[idx], output[0][idx])
                jsonArray.put(obj)
            }

            result.put("results", jsonArray)

        } catch (exception: JSONException){
            Log.e(TAG, "Exception occurred during constructing a JSON object -> ", exception)
        }

        return result
    }

    private fun Bitmap.convertBitmapToByteBuffer(): ByteBuffer{
        val byteBuffer = ByteBuffer.allocateDirect(modelInputSize)
        byteBuffer.order(ByteOrder.nativeOrder())

        val pixels = IntArray(inputImageWidth * inputImageHeight)
        this.getPixels(pixels, 0, width, 0, 0, width, height)
        var pixel = 0
        for(i in 0 until inputImageWidth){
            for(j in 0 until inputImageHeight){
                val pixelValue = pixels[pixel++]

                byteBuffer.putFloat(((pixelValue shr 16 and 0xFF) - IMAGE_MEAN) / IMAGE_STD)
                byteBuffer.putFloat(((pixelValue shr 8 and 0xFF) - IMAGE_MEAN) / IMAGE_STD)
                byteBuffer.putFloat(((pixelValue and 0xFF) - IMAGE_MEAN) / IMAGE_STD)
            }
        }

        this.recycle()

        return byteBuffer
    }

getMaxResult는 결과(Softmax를 거친 각 레이블에 대한 확률 분포) 중에서 가장 높은 값의 인덱스를 찾는다. 
classify는 ImageAnalysis.Analyzer에서 캡처한 프레임으로 만든 비트맵으로 Interpreter의 텐서플로우 그래프 연산을 통해서 결과 값을 출력하여 JSON 형태로 결과를 리턴하는 메소드이다. 

check(isInitialized) {"The interpreter mush be initialized first."}로 Interpreter가 초기화 되지 않았다면(isInitialized = false) IllegalStateException을 Throw한다.
Bitmap.createScaledBitmap로 앞에서 정의한 크기대로 크기가 조정된 비트맵을 만든다. 
convertBitmapToByteBuffer Extension function으로 비트맵을 ByteBuffer로 바꾼다.
var inferenceTime = endTime - startTime로 추론에 걸린 시간을 구한다.
interpreter?.run(byteBuffer, output)으로 ByteBuffer을 입력으로 주고 Sotfmax를 거친 클래스 확률 분포를 구한다. 
result라는 JSONObject에 걸린시간, 가장 높은 값의 인덱스, 레이블-확률 매핑한 JSONArray를 넣어 리턴한다. 

allocateDirect 메소드의 경우 JVM 힙 메모리 바깥쪽의 OS가 관리하는 메모리에 직접적으로 버퍼를 생성한다. 이때 버퍼의 크기는 앞서 구해둔 modelInputSize이다. 
nativeOrder 메소드는 Java 가상 머신이 실행되고 있는 하드웨어의 네이티브 바이트 순서를 반환한다(BIG_ENDIAN 인지 LITTEL_ENDIAN 인지).
order 메소드로 버퍼에서 바이트의 순서를 설정한다.
IntArray로 정해진 크기만큼 배열을 만들고 getPixels 메소드로 비트맵 데이터를 가져온다. 이때 각 요소 값은 Color에 대한 객체이다. 세번째 width는 row간의 stride이므로 width 값을 인자로 주어 그만큼의 데이터를 받으면 다음 row로 넘어 갈 수 있게 한다. 
for 문 안에서는 각 픽셀의 RGB값을 정규화하여 만들어 놓은 버퍼에 넣는다. 
Bitmap은 Native heap 영역에 할당되기 때문에 recyle 메소드를 호출해서 메모리 누수가 일어나지 않도록 해야 한다. 
```



