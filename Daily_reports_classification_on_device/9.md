ExecutorService, ProcessCameraProvider, CameraSelector, ImageAnalysis, Preview 등에 대한 설명이나 이들을 Lifecycleowner에 바인딩 하는 방법, 권한 요구 등에 대한 코드는 지난번 포스트를 참고.

```kotlin 
typealias RealtimeFrameListener = (bitmapImage: Bitmap) -> Unit
비트맵을 입력받아 tfLiteClassifier로 분류 작업을 수행하고 Textview에 결과를 보여주는 작업을 수행하는 리스너이다. (리스너는 특정 이벤트를 처리하는 인터페이스로, 이벤트 발생시 해당 이벤트에 맞는 처리를 수행하도록 한다. 이벤트 리스너는 사용자와 상호작용하는 이벤트 발생 시 안드로이드 프레임워크의 인터페이스를 호출한다. 이 인터 페이스를 실체화한 객체에서 이벤트에 맞는 처리를 한다.)
```

```kotlin
private val tfLiteClassifier: TFLiteClassifier = TFLiteClassifier(this)

8에서 정의한 Classifier에 관련된 객체이다. 
```

```kotlin 
private class RealtimeFrameAnalyzer(private val listener: RealtimeFrameListener): ImageAnalysis.Analyzer{
        private fun Bitmap.rotate(degrees: Float): Bitmap{
            val matrix = Matrix().apply { postRotate(degrees) }
            return Bitmap.createBitmap(this, 0, 0, width, height, matrix, true)
        }

        override fun analyze(image: ImageProxy) {
            val yBuffer = image.planes[0].buffer // Y
            val uBuffer = image.planes[1].buffer // U
            val vBuffer = image.planes[2].buffer // V

            val ySize = yBuffer.remaining()
            val uSize = uBuffer.remaining()
            val vSize = vBuffer.remaining()

            val nv21 = ByteArray(ySize + uSize + vSize)

            yBuffer.get(nv21, 0, ySize)
            vBuffer.get(nv21, ySize, vSize)
            uBuffer.get(nv21, ySize + vSize, uSize)

            val yuvImage = YuvImage(nv21, ImageFormat.NV21, image.width, image.height, null)
            val out = ByteArrayOutputStream()
            yuvImage.compressToJpeg(Rect(0, 0, yuvImage.width, yuvImage.height), 50, out)
            val imageBytes = out.toByteArray()
            val bitmapImage = BitmapFactory.decodeByteArray(imageBytes, 0, imageBytes.size).rotate(90.0.toFloat())
            listener(bitmapImage)
            image.close()
        }
    }

analyze 메소드는 실시간으로 들어오는 프레임을 비트맵으로 만들어서 리스너에게 전달해준다. 이때 image의 포맷을 확인해보면 YUV_422_888인 것을 확인할 수 있다.image.planes에는 캡처한 이미지의 Pixel plane에 대한 배열을 얻을 수 있다. YUV_422_888의 경우 3개의 차원을 갖는데. 각각 Y, U, V에 대한 값을 나타낸다. 각 Pixel Plane에 대해서는 getBuffer로 프레임 데이터에 대한 ByteBuffer 객체를 얻을 수 있다. remaining() 메소드로는 버퍼의 현재 위치와 Limit 사이의 차이만큼의 숫자를 리턴한다(즉, 여기서는 버퍼에서 데이터가 들어 있는 양). 그리고 Y, U, V의 데이터 사이즈 만큼의 ByteArray를 만들고 각 버퍼에서 데이터를 받는다. 
받은 데이터로 YuvImage 객체를 생성하고 ByteArrayOutputStream으로 이미지 크기만큼의 데이터를 JPEG 형식으로 압축한다. 
ByteArrayOutputStream으로 ByteArray를 만들고 BitmapFactory.decodeByteArray로 비트맵을 만들어서 리스너에게 전달한다. 
image.close를 호출해서 image 객체에 대한 참조를 close한다. 
Bitmap에 대한 Extension 메소드인 rotate를 정의하여 호출하는데 여기서 가져오는 이미지 프레임을 살펴보면 90 반시계로 회전한 상태이기 때문이다. 
```

```kotlin 
tfLiteClassifier.initialize()

onCreate 메소드에서 호출해서 인터프리터를 초기화 한다.
```

```kotlin 
val imageAnalyzer = ImageAnalysis.Builder()
                .build()
                .also{
                    it.setAnalyzer(cameraExecutor, RealtimeFrameAnalyzer{ bitmapImage ->
                            val resultJsonObject = tfLiteClassifier.classify(bitmapImage)
                            val time = resultJsonObject.getLong("time")
                            val maxIndex = resultJsonObject.getInt("index")
                            val jsonResults: JSONArray = resultJsonObject.getJSONArray("results")

                            val labels = tfLiteClassifier.labels

                            inferenceTime.text = "Inference Time: ${time}ms"

                            val childCount = list_item.childCount
                            for(idx in 0 until childCount){
                                val resultJsonObj: JSONObject = jsonResults.getJSONObject(idx)
                                val probString = resultJsonObj.getDouble(labels[idx]).toString()
                                val probability = DecimalFormat("0.0000").format(probString.toFloat()).toFloat()
                                val child: TextView = list_item.getChildAt(idx) as TextView

                                if(idx == maxIndex){
                                    child.text = "${labels[idx]}: $probability"
                                    child.setTextColor(Color.parseColor("#FF9800"))
                                } else {
                                    child.text = "${labels[idx]}: $probability"
                                    child.setTextColor(Color.WHITE)
                                }
                            }

                    })
                }
                    
RealtimeFrameAnalyzer에서 리스너에게 전달한 비트맵이 bitmapImage이다. 이 비트맵을 미리 정의한 인터프리터의 classify 메소드에 인자로 넣어주어 결과 JSON 객체를 리턴 받는다. JSON 객체에서 걸린 시간, 가장 큰 확률 값의 인덱스, 레이블-확률 객체값을 꺼내서 결과 View에 표시한다. 
```

결과는 다음을 참조

[온디바이스(네이티브앱)](https://www.youtube.com/watch?v=YkWjIa21Kkc&amp;feature=youtu.be)

